{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import io, stats\n",
    "import mne"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE import 1 subject\n",
    "subject = 'NI'\n",
    "id = '72_9'\n",
    "save_path = \"D:\\Files\\Master Degree\\Master Thesis\\Code\\Simulation_Result\\\\72 NI_10\\\\9\"\n",
    "\n",
    "# import all subjects\n",
    "# subject = 'NI_AR'\n",
    "# id = '73'\n",
    "# o_folder = 'D:\\Files\\Master Degree\\Master Thesis\\Code\\Simulation_Result\\\\70 AR_10'\n",
    "# y_folder = 'D:\\Files\\Master Degree\\Master Thesis\\Code\\Simulation_Result\\\\72 NI_10'\n",
    "# save_path = \"D:\\Files\\Master Degree\\Master Thesis\\Code\\Simulation_Result\\\\73 NI_AR_3\"\n",
    "# filestr = 'EEGpower20sEpochs' # 'TimeStatwithin20sResult' / EEGpowerRaw_allNodes\n",
    "\n",
    "# Nodes in PFC\n",
    "chosen_PFC = [2, 10, 12, 16, 17, 18, 25, 26, 30, 36, 44, 46, 50, 51, 52, 59, 60, 64]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_data (subs, subs_time, total, cutoff=0, stim_start=0, stim_end=0):\n",
    "  \n",
    "  start_point = np.where(subs_time == cutoff)[0][0] + 1\n",
    "  if stim_start != 0:\n",
    "    stim_period = np.where(subs_time == stim_start)[0][0] + 1 # (stim_start / 3.90625) - 1\n",
    "    stim_post = np.where(subs_time == stim_end)[0][0] + 1 # (stim_end / 3.90625) - 1\n",
    "    subs_all = subs[start_point:,:]\n",
    "    subs_pre = subs[start_point:stim_period,:]\n",
    "    subs_stim = subs[stim_period:stim_post, :]\n",
    "    if total == stim_end:\n",
    "      all_subs = [subs_all, subs_pre, subs_stim]\n",
    "      return all_subs\n",
    "    subs_post = subs[stim_post:, :]\n",
    "    all_subs = [subs_all, subs_pre, subs_stim, subs_post]\n",
    "  else: \n",
    "    subs = subs[start_point:,:]\n",
    "    all_subs = [subs]\n",
    "\n",
    "  return all_subs\n",
    "\n",
    "def computed_psd_raw(raw, fmax=np.inf):\n",
    "  spectrum = raw.compute_psd(method='welch', fmax=fmax , picks='all', n_fft=256*4, n_per_seg=256*4)\n",
    "  psds, freqs = spectrum.get_data(return_freqs=True, picks='all')\n",
    "\n",
    "  return spectrum, [psds, freqs]\n",
    "\n",
    "def computed_psd_eachEpochs(epochs, fmax=np.inf):\n",
    "  epo_spectrum = epochs.compute_psd(method='welch', fmax=fmax ,picks='all', n_fft=256*4, n_per_seg=256*4)\n",
    "  psds, freqs = epo_spectrum.get_data(return_freqs=True, picks='all')\n",
    "\n",
    "  return epo_spectrum, [psds, freqs]\n",
    "\n",
    "def kstest(data):\n",
    "  result = stats.ks_1samp(data, stats.norm.cdf)\n",
    "\n",
    "  return result\n",
    "\n",
    "def bandpower(psd, f, band):\n",
    "    \"\"\"\n",
    "    https://raphaelvallat.com/bandpower.html\n",
    "    Compute the average power of the signal x in a specific frequency band.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1d-array\n",
    "        Input signal in the time-domain.\n",
    "    sf : float\n",
    "        Sampling frequency of the data.\n",
    "    band : list\n",
    "        Lower and upper frequencies of the band of interest.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    bp : float\n",
    "        Absolute or relative band power.\n",
    "    \"\"\"\n",
    "    from scipy.integrate import simps\n",
    "    band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    # Frequency resolution\n",
    "    freq_res = f[1] - f[0]\n",
    "\n",
    "    # Find closest indices of band in frequency vector\n",
    "    idx_band = np.logical_and(f >= low, f <= high)\n",
    "\n",
    "    # Integral approximation of the spectrum using Simpson's rule.\n",
    "    absolutep = simps(psd[idx_band], dx=freq_res)\n",
    "    total_power = simps(psd, dx=freq_res)\n",
    "    relative = absolutep / total_power\n",
    "    \n",
    "    return absolutep, relative\n",
    "\n",
    "# calculate EEG power for each node in each segment\n",
    "def powerEEGraw(data, prefix, mode='99'):\n",
    "\n",
    "  eegpow = {}\n",
    "\n",
    "  for p in range(len(prefix)):\n",
    "    dat = data[prefix[p]]\n",
    "    power = []\n",
    "    for i in range(68):\n",
    "      absolute_swa, relative_swa = bandpower(psd=dat[0][0][i], f=dat[0][1][0], band=[0.5, 4])\n",
    "      absolute_os, relative_os = bandpower(psd=dat[0][0][i], f=dat[0][1][0], band=[0.5, 1])\n",
    "      absolute_delta, relative_delta = bandpower(psd=dat[0][0][i], f=dat[0][1][0], band=[1, 4])\n",
    "      absolute_theta, relative_theta = bandpower(psd=dat[0][0][i], f=dat[0][1][0], band=[4, 8])\n",
    "      absolute_slowspin, relative_slowspin = bandpower(psd=dat[0][0][i], f=dat[0][1][0], band=[8, 12])\n",
    "      absolute_fastspin, relative_fastspin = bandpower(psd=dat[0][0][i], f=dat[0][1][0], band=[12, 15])\n",
    "      absolute_rest, relative_rest = bandpower(psd=dat[0][0][i], f=dat[0][1][0], band=[15, 130])\n",
    "\n",
    "      abpow = [absolute_swa, absolute_os, absolute_delta, absolute_theta, absolute_slowspin, absolute_fastspin,absolute_rest]\n",
    "      relpow = [relative_swa, relative_os, relative_delta, relative_theta, relative_slowspin, relative_fastspin, relative_rest]\n",
    "      power.append([abpow, relpow])\n",
    "\n",
    "    eegpow[prefix[p]] = np.array(power, dtype=object)\n",
    "\n",
    "  eegpower = save_path + '/EEGpowerRaw_' + mode + '_' + subject + '_' + id + '.mat'\n",
    "  io.savemat(eegpower, mdict=eegpow)\n",
    "\n",
    "  return eegpow, eegpower\n",
    "\n",
    "def mean_power(data, prefix, axis=0):\n",
    "  \"\"\"\n",
    "  result: (simulation round, power, frequency band)\n",
    "  power: 0 = absolute power, 1 = relative power\n",
    "  frequency band: 0 = swa, 1 = os, 2 = delta, 3 = theta, 4 = slowspin, 5 = fastspin, 6 = rest\n",
    "  \"\"\"\n",
    "  new = {}\n",
    "  for i in prefix:\n",
    "    new[i] = data[i].mean(axis=axis)\n",
    "\n",
    "  return new\n",
    "\n",
    "def getallEEGpow(path, filestr):\n",
    "\n",
    "  directory = os.fsencode(path)\n",
    "  subjects_psd = {}\n",
    "  all = []\n",
    "  pre = []\n",
    "  stim = []\n",
    "  post = []\n",
    "\n",
    "  for i, folder in enumerate(os.listdir(directory)):\n",
    "    foldername = os.fsdecode(folder)\n",
    "    if foldername == 'desktop.ini' or 'within' in foldername:\n",
    "      continue\n",
    "    subpath = path + '/' + foldername\n",
    "    subdirec = os.fsencode(subpath)\n",
    "\n",
    "    for j, file in enumerate(os.listdir(subdirec)):\n",
    "      filename = os.fsdecode(file)\n",
    "      filename_path = subpath + '/' + filename\n",
    "      if filename.startswith(filestr) and filename.endswith(\".mat\"):\n",
    "        psdsub = io.loadmat(filename_path)\n",
    "        # all.append(psdsub['psd raw all'])\n",
    "        # pre.append(psdsub['psd raw prestim'])\n",
    "        # stim.append(psdsub['psd raw stimon'])\n",
    "        # post.append(psdsub['psd raw poststim'])\n",
    "        all.append(psdsub['psd epo all'])\n",
    "        pre.append(psdsub['psd epo prestim'])\n",
    "        stim.append(psdsub['psd epo stimon'])\n",
    "        post.append(psdsub['psd epo poststim'])\n",
    "\n",
    "  subjects_psd['power all'] = np.array(all, dtype=object)\n",
    "  subjects_psd['power pre'] = np.array(pre, dtype=object)\n",
    "  subjects_psd['power stim'] = np.array(stim, dtype=object)\n",
    "  subjects_psd['power post'] = np.array(post, dtype=object)\n",
    "\n",
    "  return subjects_psd\n",
    "\n",
    "# compute mean of relative power each rounds PFC, 3 bands\n",
    "def meanstdpfc_power(data, prefix, chosen=chosen_PFC):\n",
    "  new = {}\n",
    "  for i in prefix:\n",
    "    m = data[i][:, chosen, 1, :3].mean(axis=1)\n",
    "    s = np.std(data[i][:, chosen, 1, :3].astype(np.float64), axis=1)\n",
    "\n",
    "    new[i] = np.array([m, s])\n",
    "\n",
    "  return new\n",
    "\n",
    "# calculate EEG power for each node in each epoch \n",
    "def powerEEGepo(data, prefix):\n",
    "\n",
    "  eegpow = {}\n",
    "\n",
    "  for p in range(len(prefix)):\n",
    "    dat = data[prefix[p]]\n",
    "    num = dat[0][0].shape[0]\n",
    "    allpow = []\n",
    "    for i in range(num):\n",
    "      power = []\n",
    "      for j in range(68):\n",
    "        absolute_swa, relative_swa = bandpower(psd=dat[0][0][i][j], f=dat[0][1][0], band=[0.5, 4])\n",
    "        absolute_os, relative_os = bandpower(psd=dat[0][0][i][j], f=dat[0][1][0], band=[0.5, 1])\n",
    "        absolute_delta, relative_delta = bandpower(psd=dat[0][0][i][j], f=dat[0][1][0], band=[1, 4])\n",
    "        absolute_theta, relative_theta = bandpower(psd=dat[0][0][i][j], f=dat[0][1][0], band=[4, 8])\n",
    "        absolute_slowspin, relative_slowspin = bandpower(psd=dat[0][0][i][j], f=dat[0][1][0], band=[8, 12])\n",
    "        absolute_fastspin, relative_fastspin = bandpower(psd=dat[0][0][i][j], f=dat[0][1][0], band=[12, 15])\n",
    "        absolute_rest, relative_rest = bandpower(psd=dat[0][0][i][j], f=dat[0][1][0], band=[15, 130])\n",
    "\n",
    "        abpow = [absolute_swa, absolute_os, absolute_delta, absolute_theta, absolute_slowspin, absolute_fastspin,absolute_rest]\n",
    "        relpow = [relative_swa, relative_os, relative_delta, relative_theta, relative_slowspin, relative_fastspin, relative_rest]\n",
    "        power.append([abpow, relpow])\n",
    "\n",
    "      allpow.append(power)\n",
    "    eegpow[prefix[p]] = np.array(allpow, dtype=object)\n",
    "\n",
    "  eegpower = save_path + '/EEGpower12sEpochs_' + subject + '_' + id + '.mat'\n",
    "  io.savemat(eegpower, mdict=eegpow)\n",
    "\n",
    "  return eegpow, eegpower\n",
    "\n",
    "def convert_zscore(data, prefix, axis=None):\n",
    "  # concatenate pre-stim-post together\n",
    "  con_data = np.concatenate((data[prefix[1]], data[prefix[2]], data[prefix[3]]), axis=1)\n",
    "  znew = stats.zscore(con_data.astype(np.float64), axis=axis)\n",
    "\n",
    "  return znew\n",
    "\n",
    "def prep_FC(FC):\n",
    "\n",
    "  fc = []\n",
    "  for i in range(10):\n",
    "    FC[i][np.diag_indices_from(FC[i])] = 0 # changing the diagonal (self_connections) to 0.\n",
    "    idxs = np.triu_indices_from(FC[i], k=1)\n",
    "    # choosing only upper traingle of FC matrix \n",
    "    triu_FC = np.asarray(FC[i][idxs])\n",
    "    fc.append(triu_FC)\n",
    "\n",
    "  return fc\n",
    "\n",
    "def getallfc(path, filestr):\n",
    "\n",
    "  directory = os.fsencode(path)\n",
    "  subjects_psd = {}\n",
    "  all = []\n",
    "  pre = []\n",
    "  stim = []\n",
    "  post = []\n",
    "  pfcall = []\n",
    "  pfcpre = []\n",
    "  pfcstim = []\n",
    "  pfcpost = []\n",
    "\n",
    "  for i, folder in enumerate(os.listdir(directory)):\n",
    "    foldername = os.fsdecode(folder)\n",
    "    if foldername == 'desktop.ini' or 'within' in foldername:\n",
    "      continue\n",
    "    subpath = path + '/' + foldername\n",
    "    subdirec = os.fsencode(subpath)\n",
    "\n",
    "    for j, file in enumerate(os.listdir(subdirec)):\n",
    "      filename = os.fsdecode(file)\n",
    "      filename_path = subpath + '/' + filename\n",
    "      if filename.startswith(filestr) and filename.endswith(\".mat\"):\n",
    "        psdsub = io.loadmat(filename_path)\n",
    "        all.append(psdsub['all fc'])\n",
    "        pre.append(psdsub['pre fc'])\n",
    "        stim.append(psdsub['stim fc'])\n",
    "        post.append(psdsub['post fc'])\n",
    "        pfcall.append(psdsub['pfc fc'])\n",
    "        pfcpre.append(psdsub['pfc pre fc'])\n",
    "        pfcstim.append(psdsub['pfc stim fc'])\n",
    "        pfcpost.append(psdsub['pfc post fc'])\n",
    "\n",
    "  subjects_psd['all fc'] = np.array(all, dtype=object)\n",
    "  subjects_psd['pre fc'] = np.array(pre, dtype=object)\n",
    "  subjects_psd['stim fc'] = np.array(stim, dtype=object)\n",
    "  subjects_psd['post fc'] = np.array(post, dtype=object)\n",
    "  subjects_psd['pfc fc'] = np.array(pfcall, dtype=object)\n",
    "  subjects_psd['pfc pre fc'] = np.array(pfcpre, dtype=object)\n",
    "  subjects_psd['pfc stim fc'] = np.array(pfcstim, dtype=object)\n",
    "  subjects_psd['pfc post fc'] = np.array(pfcpost, dtype=object)\n",
    "\n",
    "  return subjects_psd\n",
    "\n",
    "def ind_ttest(data1, data2, alternative='two-sided', axis=0):\n",
    "  norm1 = stats.shapiro(data1.flatten())\n",
    "  norm2 = stats.shapiro(data2.flatten())\n",
    "\n",
    "  homo = stats.levene(data1.flatten(), data2.flatten())\n",
    "\n",
    "  n1 = data1.flatten().shape[0]\n",
    "  n2 = data1.flatten().shape[0]\n",
    "  df = (n1 + n2) - 2 \n",
    "\n",
    "  if homo[1] >= 0.05:\n",
    "    test = stats.ttest_ind(a=data1, b=data2, axis=axis, equal_var=True, alternative=alternative) # default is 2 tailed\n",
    "  else:\n",
    "    test = stats.ttest_ind(a=data1, b=data2, axis=axis, equal_var=False, alternative=alternative) # default is 2 tailed\n",
    "  \n",
    "  return norm1, norm2, homo, df, test\n",
    "\n",
    "def paired_ttest(data1, data2, alternative='two-sided', axis=None):\n",
    "  norm1 = stats.shapiro(data1.flatten())\n",
    "  norm2 = stats.shapiro(data2.flatten())\n",
    "\n",
    "  n = data1.flatten().shape[0]\n",
    "  df = n - 1 \n",
    "\n",
    "  test = stats.ttest_rel(a=data1, b=data2, alternative=alternative, axis=axis) # default is 2 tailed\n",
    "  \n",
    "  return norm1, norm2, df, test\n",
    "\n",
    "def getbetweenfc(path, filestr):\n",
    "\n",
    "  directory = os.fsencode(path)\n",
    "\n",
    "  for i, folder in enumerate(os.listdir(directory)):\n",
    "    foldername = os.fsdecode(folder)\n",
    "    if foldername == 'desktop.ini':\n",
    "      continue\n",
    "    subpath = path + '/' + foldername\n",
    "    subdirec = os.fsencode(subpath)\n",
    "\n",
    "    if foldername.startswith(filestr) and foldername.endswith(\".mat\"):\n",
    "      fcsub = io.loadmat(subpath)\n",
    "\n",
    "  return fcsub\n",
    "\n",
    "def findSlope(datax, datay1, datay2, freq=0):\n",
    "  slopeList = []\n",
    "\n",
    "  for i in range(10):\n",
    "      y = np.array([datay1[i, 1, freq], datay2[i, 1, freq]]).flatten().astype(np.float64)\n",
    "      slope, _, _, _, _ = stats.linregress(datax, y)\n",
    "      slopeList.append(slope)\n",
    "  \n",
    "  return slopeList\n",
    "\n",
    "def findSlopepfc(datax, datay1, datay2, freq=0):\n",
    "  slopeList = []\n",
    "\n",
    "  for i in range(10):\n",
    "      y = np.array([datay1[0, i, freq], datay2[0, i, freq]]).flatten().astype(np.float64)\n",
    "      slope, _, _, _, _ = stats.linregress(datax, y)\n",
    "      slopeList.append(slope)\n",
    "  \n",
    "  return slopeList"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSD Estimation in MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import simulation result\n",
    "filesimname = 'NI_72_9.mat'\n",
    "\n",
    "cutoff = 2000\n",
    "stim_start = 60000 \n",
    "stim_end = 120000\n",
    "total = 180000\n",
    "\n",
    "# prepare data\n",
    "filepath = save_path + '/' + filesimname\n",
    "subs = io.loadmat(filepath)['subs_data'].mean(axis=1) # mean signal from both excitatory and inhibitory subpopulations\n",
    "subs_time =io.loadmat(filepath)['subs_time'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata\n",
    "n_channels = 68\n",
    "sampling_freq = 256  # in Hertz # from 46080 (samples) / 180 sec (simulation length)\n",
    "info = mne.create_info(n_channels, sfreq=sampling_freq)\n",
    "\n",
    "all_subs = divide_data (subs, subs_time, total, cutoff=cutoff, stim_start=stim_start, stim_end=stim_end)\n",
    "\n",
    "raw = mne.io.RawArray(all_subs[0].T, info)\n",
    "# read raw simulation results (no epoch)\n",
    "rawpre = mne.io.RawArray(all_subs[1].T, info) # cutoff another 2 sec\n",
    "rawstim = mne.io.RawArray(all_subs[2][:-512].T, info) # cutoff 4 sec\n",
    "rawpost = mne.io.RawArray(all_subs[3][:-512].T, info) # cutoff 4 sec\n",
    "\n",
    "# raw for 20-s epochs\n",
    "# rawpre = mne.io.RawArray(all_subs[1][4608:].T, info) # cutoff another 18 sec\n",
    "# rawstim = mne.io.RawArray(all_subs[2][:].T, info)\n",
    "# rawpost = mne.io.RawArray(all_subs[3][:].T, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute PSD on raw data\n",
    "rawobj_all, rawall_psd = computed_psd_raw(raw)\n",
    "rawobj_pre, rawpre_psd = computed_psd_raw(rawpre)\n",
    "rawobj_stim, rawstim_psd = computed_psd_raw(rawstim)\n",
    "rawobj_post, rawpost_psd = computed_psd_raw(rawpost)\n",
    "\n",
    "# compute PSD for each epoch\n",
    "# eduration = 20\n",
    "\n",
    "# epochs = mne.make_fixed_length_epochs(raw, duration=eduration, preload=True)\n",
    "# prestim = mne.make_fixed_length_epochs(rawpre, duration=eduration, preload=False)\n",
    "# stimon = mne.make_fixed_length_epochs(rawstim, duration=eduration, preload=False)\n",
    "# poststim = mne.make_fixed_length_epochs(rawpost, duration=eduration, preload=False)\n",
    "\n",
    "# epoobj_all, epoall_psd = computed_psd_eachEpochs(epochs)\n",
    "# epoobj_pre, prestim_psd = computed_psd_eachEpochs(prestim)\n",
    "# epoobj_stim, stimon_psd = computed_psd_eachEpochs(stimon)\n",
    "# epoobj_post, poststim_psd = computed_psd_eachEpochs(poststim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export raw PSD\n",
    "psdrawresult = save_path + '/PSDrawpfcResult_' + subject + '_' + id + '.mat'\n",
    "io.savemat(psdrawresult, mdict={\n",
    "  'psd raw all': np.array((rawall_psd), dtype=object),\n",
    "  'psd raw prestim': np.array((rawpre_psd), dtype=object),\n",
    "  'psd raw stimon': np.array((rawstim_psd), dtype=object),\n",
    "  'psd raw poststim': np.array((rawpost_psd), dtype=object)\n",
    "})\n",
    "\n",
    "# export epochs PSD\n",
    "# psdepresult = save_path + '/PSDepochspfc20sResult_' + subject + '_' + id + '.mat'\n",
    "# io.savemat(psdepresult, mdict={\n",
    "#   'psd epo all': np.array((epoall_psd), dtype=object),\n",
    "#   'psd epo prestim': np.array((prestim_psd), dtype=object),\n",
    "#   'psd epo stimon': np.array((stimon_psd), dtype=object),\n",
    "#   'psd epo poststim': np.array((poststim_psd), dtype=object)\n",
    "# })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Relative power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PSD\n",
    "psdfilename = ''\n",
    "psdpath = save_path + '/' + psdfilename\n",
    "sub_psd = io.loadmat(psdpath)\n",
    "\n",
    "prefix_rawpsd = ['psd raw all', 'psd raw prestim', 'psd raw stimon', 'psd raw poststim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from all nodes\n",
    "eegpowraw_all, pathtopowerraw = powerEEGraw(sub_psd, prefix=prefix_rawpsd, mode='allNodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all subjects\n",
    "youngpower = getallEEGpow(path=y_folder, filestr=filestr)\n",
    "oldpower = getallEEGpow(path=o_folder, filestr=filestr)\n",
    "\n",
    "# mean relative power of 10 rounds for each node\n",
    "prefix_pow = ['power all', 'power pre', 'power stim', 'power post']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test relative power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean power across all nodes for each round\n",
    "mean_youngpower = mean_power(data=youngpower, prefix=prefix_pow, axis=1)\n",
    "mean_oldpower = mean_power(data=oldpower, prefix=prefix_pow, axis=1)\n",
    "\n",
    "testdata1 = mean_youngpower.copy()\n",
    "testdata2 = mean_oldpower.copy()\n",
    "\n",
    "# test normality\n",
    "swapow_pre_normy = kstest(data=testdata1[prefix_pow[1]][:, 1, 0].flatten().astype(np.float64))\n",
    "ospow_pre_normy = kstest(data=testdata1[prefix_pow[1]][:, 1, 1].flatten().astype(np.float64))\n",
    "delpow_pre_normy = kstest(data=testdata1[prefix_pow[1]][:, 1, 2].flatten().astype(np.float64))\n",
    "swapow_pre_normo = kstest(data=testdata2[prefix_pow[1]][:, 1, 0].flatten().astype(np.float64))\n",
    "ospow_pre_normo = kstest(data=testdata2[prefix_pow[1]][:, 1, 1].flatten().astype(np.float64))\n",
    "delpow_pre_normo = kstest(data=testdata2[prefix_pow[1]][:, 1, 2].flatten().astype(np.float64))\n",
    "\n",
    "# calculate median and interquartile range (IQR)\n",
    "data1 = np.array([testdata1[p][:, 1, :3] for p in prefix_pow[1:]]).astype(np.float64) # data1 = (session, rounds, frequency)\n",
    "data2 = np.array([testdata2[p][:, 1, :3] for p in prefix_pow[1:]]).astype(np.float64)\n",
    "med = np.median(data1[2, :, 0])\n",
    "q1, q3 = np.percentile(data1[2, :, 0], [25, 75])\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Mann-Whitney U test\n",
    "# t-test young has SWA more than old --> young (data1) greater than old (data2)\n",
    "testpremyoswa = stats.mannwhitneyu(testdata1[prefix_pow[1]][:, 1, 0].astype(np.float64), testdata2[prefix_pow[1]][:, 1, 0].astype(np.float64), axis=0, alternative='greater')\n",
    "testpremyoos = stats.mannwhitneyu(testdata1[prefix_pow[1]][:, 1, 1].astype(np.float64), testdata2[prefix_pow[1]][:, 1, 1].astype(np.float64), axis=0, alternative='greater')\n",
    "testpremyodel = stats.mannwhitneyu(testdata1[prefix_pow[1]][:, 1, 2].astype(np.float64), testdata2[prefix_pow[1]][:, 1, 2].astype(np.float64), axis=0, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean power across PFC nodes for each round\n",
    "mstdpfc_ypow = meanstdpfc_power(data=youngpower, prefix=prefix_pow)\n",
    "mstdpfc_opow = meanstdpfc_power(data=oldpower, prefix=prefix_pow)\n",
    "\n",
    "# test normality\n",
    "testdata1 = mstdpfc_ypow.copy()\n",
    "testdata2 = mstdpfc_opow.copy()\n",
    "\n",
    "swapow_pre_normy = kstest(data=testdata1[prefix_pow[1]][0, :, 0].flatten().astype(np.float64))\n",
    "ospow_pre_normy = kstest(data=testdata1[prefix_pow[1]][0, :, 1].flatten().astype(np.float64))\n",
    "delpow_pre_normy = kstest(data=testdata1[prefix_pow[1]][0, :, 2].flatten().astype(np.float64))\n",
    "swapow_pre_normo = kstest(data=testdata2[prefix_pow[1]][0, :, 0].flatten().astype(np.float64))\n",
    "ospow_pre_normo = kstest(data=testdata2[prefix_pow[1]][0, :, 1].flatten().astype(np.float64))\n",
    "delpow_pre_normo = kstest(data=testdata2[prefix_pow[1]][0, :, 2].flatten().astype(np.float64))\n",
    "\n",
    "# calculate median and interquartile range (IQR)\n",
    "data1 = np.array([testdata1[p][0, :, :3] for p in prefix_pow[1:]]).astype(np.float64) \n",
    "data2 = np.array([testdata2[p][0, :, :3] for p in prefix_pow[1:]]).astype(np.float64)\n",
    "med = np.median(data1[2, :, 0])\n",
    "q1, q3 = np.percentile(data1[2, :, 0], [25, 75])\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Mann-Whitney U test\n",
    "# t-test young has SWA more than old --> young (data1) greater than old (data2)\n",
    "testprempfcyoswa = stats.mannwhitneyu(testdata1[prefix_pow[1]][0, :, 0].astype(np.float64), testdata2[prefix_pow[1]][0, :, 0].astype(np.float64), axis=0, alternative='greater')\n",
    "testprempfcyoos = stats.mannwhitneyu(testdata1[prefix_pow[1]][0, :, 1].astype(np.float64), testdata2[prefix_pow[1]][0, :, 1].astype(np.float64), axis=0, alternative='greater')\n",
    "testprempfcyodel = stats.mannwhitneyu(testdata1[prefix_pow[1]][0, :, 2].astype(np.float64), testdata2[prefix_pow[1]][0, :, 2].astype(np.float64), axis=0, alternative='greater')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of so-tDCS over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PSD\n",
    "psdfilename = ''\n",
    "psdpath = save_path + '/' + psdfilename\n",
    "sub_psd = io.loadmat(psdpath)\n",
    "\n",
    "# compute PSD for each epoch\n",
    "prefix_epopsd = ['psd epo all', 'psd epo prestim', 'psd epo stimon', 'psd epo poststim']\n",
    "eegpowepo_all, pathtopowerepo = powerEEGepo(data=sub_psd, prefix=prefix_epopsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all subjects\n",
    "youngpower = getallEEGpow(path=y_folder, filestr=filestr)\n",
    "oldpower = getallEEGpow(path=o_folder, filestr=filestr)\n",
    "\n",
    "# combine young & old into 1 array before computing z-score from 20 rounds\n",
    "# all nodes\n",
    "allpower = {}\n",
    "prefix_pow = ['power all', 'power pre', 'power stim', 'power post']\n",
    "for i in prefix_pow:\n",
    "  allpower[i] = np.concatenate((youngpower[i][:, :, :, 0, 0], oldpower[i][:, :, :, 0, 0]), axis=0)\n",
    "\n",
    "# Convert all absolute power into z-score\n",
    "zwhole_power = convert_zscore(data=allpower, prefix=prefix_pow, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test normality with Kolmogorov-Smirnov (KS) test\n",
    "# z-score from whole array\n",
    "testdata = zwhole_power\n",
    "\n",
    "swa_norm = {}\n",
    "normo = []\n",
    "normy = []\n",
    "for i in range(8):\n",
    "  swazwh_normy = kstest(data=testdata[:10, i, :].flatten().astype(np.float64))\n",
    "  swazwh_normo = kstest(data=testdata[10:, i, :].flatten().astype(np.float64))\n",
    "  normy.append(swazwh_normy)\n",
    "  normo.append(swazwh_normo)\n",
    "\n",
    "swa_norm['young'] = normy\n",
    "swa_norm['old'] = normo\n",
    "\n",
    "# median (interquartile range [IQR])\n",
    "y = testdata[:10, :, :]\n",
    "o = testdata[10:, :, :]\n",
    "med_y = np.median(y, axis=0)\n",
    "med_o = np.median(o, axis=0)\n",
    "\n",
    "q13y = np.percentile(y, [25, 75], axis=0)\n",
    "q13o = np.percentile(o, [25, 75], axis=0)\n",
    "iqry = q13y[1] - q13y[0]\n",
    "iqro = q13o[1] - q13o[0]\n",
    "\n",
    "# test SWA all nodes with two-tailed Mann-Whitney U test \n",
    "# pre\n",
    "testyozswa = stats.mannwhitneyu(testdata[:10, :, :], testdata[10:, :, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test slope of relative power\n",
    "- slope pre-stim and stim-on\n",
    "- slope stim-on and post-stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global SWA\n",
    "yps_slopeswa = findSlope(datax=[0,1], datay1=mean_youngpower[prefix_pow[1]], datay2=mean_youngpower[prefix_pow[2]])\n",
    "ysp_slopeswa = findSlope(datax=[1,2], datay1=mean_youngpower[prefix_pow[2]], datay2=mean_youngpower[prefix_pow[3]])\n",
    "ops_slopeswa = findSlope(datax=[0,1], datay1=mean_oldpower[prefix_pow[1]], datay2=mean_oldpower[prefix_pow[2]])\n",
    "osp_slopeswa = findSlope(datax=[1,2], datay1=mean_oldpower[prefix_pow[2]], datay2=mean_oldpower[prefix_pow[3]])\n",
    "\n",
    "dataslope = np.array([yps_slopeswa, ysp_slopeswa, ops_slopeswa, osp_slopeswa])\n",
    "\n",
    "# ks-test\n",
    "swapow_ps_normy = kstest(data=dataslope[0])\n",
    "swapow_sp_normy = kstest(data=dataslope[1])\n",
    "swapow_ps_normo = kstest(data=dataslope[2])\n",
    "swapow_sp_normo = kstest(data=dataslope[4])\n",
    "\n",
    "# Mann-whiteney test\n",
    "mtestpsyoswa = stats.mannwhitneyu(dataslope[0], dataslope[2], axis=0)\n",
    "mtestspyoswa = stats.mannwhitneyu(dataslope[1], dataslope[3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PFC SWA\n",
    "yps_slopeswa = findSlopepfc(datax=[0,1], datay1=mstdpfc_ypow[prefix_pow[1]], datay2=mstdpfc_ypow[prefix_pow[2]])\n",
    "ysp_slopeswa = findSlopepfc(datax=[1,2], datay1=mstdpfc_ypow[prefix_pow[2]], datay2=mstdpfc_ypow[prefix_pow[3]])\n",
    "ops_slopeswa = findSlopepfc(datax=[0,1], datay1=mstdpfc_opow[prefix_pow[1]], datay2=mstdpfc_opow[prefix_pow[2]])\n",
    "osp_slopeswa = findSlopepfc(datax=[1,2], datay1=mstdpfc_opow[prefix_pow[2]], datay2=mstdpfc_opow[prefix_pow[3]])\n",
    "\n",
    "dataslope = np.array([yps_slopeswa, ysp_slopeswa, ops_slopeswa, osp_slopeswa])\n",
    "\n",
    "# ks-test\n",
    "swapfc_ps_normy = kstest(data=dataslope[0])\n",
    "swapfc_sp_normy = kstest(data=dataslope[1])\n",
    "swapfc_ps_normo = kstest(data=dataslope[2])\n",
    "swapfc_sp_normo = kstest(data=dataslope[4])\n",
    "\n",
    "# Mann-whiteney test\n",
    "mtestpspfcyoswa = stats.mannwhitneyu(dataslope[0], dataslope[2], axis=0)\n",
    "mtestsppfcyoswa = stats.mannwhitneyu(dataslope[1], dataslope[3], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a simulated BOLD\n",
    "bold_data = io.loadmat(filepath)['bold_data']\n",
    "bold_time = io.loadmat(filepath)['bold_time'][0]\n",
    "\n",
    "# segment data \n",
    "all_bolds = divide_data(subs=bold_data, subs_time=bold_time, total=total, cutoff=cutoff, stim_start=stim_start, stim_end=stim_end)\n",
    "prefix = ['all data', 'pre-stim', 'stim-on', 'post-stim']\n",
    "\n",
    "# compute simulated FC\n",
    "# use method without remove upper triangle because they didn't done that in reference work\n",
    "simbold = np.squeeze(all_bolds[0][:, :, :, :].mean(axis=(1,3))).T\n",
    "all_simFC = np.corrcoef(simbold)\n",
    "all_simFC[np.diag_indices_from(all_simFC)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computed fc matrix for all, pre, stim post from all nodes & pfc\n",
    "\n",
    "data = [all_bolds[0][:, :, chosen_PFC, :], all_bolds[1][:, :, chosen_PFC, :], all_bolds[2][:, :, chosen_PFC, :], all_bolds[3][:, :, chosen_PFC, :]]\n",
    "prefix_fc = ['pfc fc', 'pfc pre fc', 'pfc stim fc', 'pfc post fc']\n",
    "all_fcs = {}\n",
    "\n",
    "for i in range(8):\n",
    "  bold = np.squeeze(data[i].mean(axis=(1,3))).T\n",
    "  all_simFC = np.corrcoef(bold)\n",
    "  all_simFC[np.diag_indices_from(all_simFC)] = 0\n",
    "\n",
    "  all_fcs[prefix_fc[i]] = all_simFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation pre-stim, pre-post, stim-post fc for each round --> save correlation of each round\n",
    "allfc = getallfc(path=save_path, filestr=filestr)\n",
    "\n",
    "prefc_tri = prep_FC(allfc[prefix_fc[1]])\n",
    "stimfc_tri = prep_FC(allfc[prefix_fc[2]])\n",
    "postfc_tri = prep_FC(allfc[prefix_fc[3]])\n",
    "\n",
    "corr_all = {}\n",
    "ps = []\n",
    "pp = []\n",
    "sp = []\n",
    "\n",
    "for i in range(10):\n",
    "  corfc_prestim = np.corrcoef(prefc_tri[i].astype(np.float64), stimfc_tri [i].astype(np.float64))[0,1]\n",
    "  corfc_prepost = np.corrcoef(prefc_tri[i].astype(np.float64), postfc_tri[i].astype(np.float64))[0,1]\n",
    "  corfc_stimpost = np.corrcoef(stimfc_tri[i].astype(np.float64), postfc_tri[i].astype(np.float64))[0,1]\n",
    "  ps.append(corfc_prestim)\n",
    "  pp.append(corfc_prepost)\n",
    "  sp.append(corfc_stimpost)\n",
    "\n",
    "corr_all['cor pre-stim'] = ps\n",
    "corr_all['cor pre-post'] = pp\n",
    "corr_all['corr stim-post'] = sp \n",
    "\n",
    "# compute mean correlation on PFC FC\n",
    "mean_corr = np.vstack([np.array(prefc_tri).mean(axis=1), np.array(stimfc_tri).mean(axis=1), np.array(postfc_tri).mean(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test on correlation of correlation\n",
    "youngfc = getbetweenfc(path=y_folder, filestr=filestr)\n",
    "oldfc = getbetweenfc(path=o_folder, filestr=filestr)\n",
    "\n",
    "prefix = ['correlation pre-stim PFC', 'correlation pre-post PFC', 'correlation stim-post PFC', 'mean correlation PFC FC 10 rounds']\n",
    "\n",
    "_, _, homopspfc, dfpspfc, testpspfc = ind_ttest(youngfc[prefix[0]], oldfc[prefix[0]], axis=1)\n",
    "_, _, homopppfc, dfpppfc, testpppfc = ind_ttest(youngfc[prefix[1]], oldfc[prefix[1]], axis=1)\n",
    "_, _, homosppfc, dfsppfc, testsppfc = ind_ttest(youngfc[prefix[2]], oldfc[prefix[2]], axis=1)\n",
    "\n",
    "# t-test on mean correlation between subject\n",
    "_, _, homoprepfc, dfprepfc, testprepfc = ind_ttest(youngfc[prefix[3]][0, :].flatten().astype(np.float64), oldfc[prefix[3]][0, :].flatten().astype(np.float64), axis=0)\n",
    "_, _, homostimpfc, dfstimpfc, teststimpfc = ind_ttest(youngfc[prefix[3]][1, :].flatten().astype(np.float64), oldfc[prefix[3]][1, :].flatten().astype(np.float64), axis=0)\n",
    "_, _, homopostpfc, dfpostpfc, testpostpfc = ind_ttest(youngfc[prefix[3]][2, :].flatten().astype(np.float64), oldfc[prefix[3]][2, :].flatten().astype(np.float64), axis=0)\n",
    "\n",
    "# t-test on mean correlation within subject\n",
    "# young\n",
    "a, b, dfprepfc, testprepfc = paired_ttest(youngfc[prefix[3]][0, :].flatten().astype(np.float64), youngfc[prefix[3]][1, :].flatten().astype(np.float64))\n",
    "c, d, dfstimpfc, teststimpfc = paired_ttest(youngfc[prefix[3]][1, :].flatten().astype(np.float64), youngfc[prefix[3]][2, :].flatten().astype(np.float64))\n",
    "e, f, dfpostpfc, testpostpfc = paired_ttest(youngfc[prefix[3]][0, :].flatten().astype(np.float64), youngfc[prefix[3]][2, :].flatten().astype(np.float64))\n",
    "# old\n",
    "a, b, dfprepfc, testprepfc = paired_ttest(oldfc[prefix[3]][0, :].flatten().astype(np.float64), oldfc[prefix[3]][1, :].flatten().astype(np.float64))\n",
    "c, d, dfstimpfc, teststimpfc = paired_ttest(oldfc[prefix[3]][1, :].flatten().astype(np.float64), oldfc[prefix[3]][2, :].flatten().astype(np.float64))\n",
    "e, f, dfpostpfc, testpostpfc = paired_ttest(oldfc[prefix[3]][0, :].flatten().astype(np.float64), oldfc[prefix[3]][2, :].flatten().astype(np.float64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c25038ab6f43c25bb083f5ca36f00e4002134afafaea969cca53c698124531e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
